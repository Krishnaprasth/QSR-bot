# QSR CEO Bot - Final Full Logic App
import streamlit as st
import pandas as pd
import openai
import chromadb
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction

st.set_page_config(page_title="QSR CEO Bot", layout="wide")
st.title("🍔 QSR CEO Performance Bot")

uploaded_file = st.file_uploader("Upload final_cleaned_50_months.csv", type=["csv"])
if not uploaded_file:
    st.warning("Please upload the final_cleaned_50_months.csv to begin.")
    st.stop()

df = pd.read_csv(uploaded_file)
df['Month'] = pd.to_datetime(df['Month'], format='%b-%y', errors='coerce')

api_key = st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else st.text_input("Enter OpenAI API Key", type="password")
if not api_key:
    st.warning("Please enter your OpenAI API key to proceed.")
    st.stop()
openai.api_key = api_key

# Vector Search Setup
embedding_function = OpenAIEmbeddingFunction(api_key=api_key)
chroma_client = chromadb.Client()
collection = chroma_client.get_or_create_collection("qsr_ceo_questions", embedding_function=embedding_function)

if len(collection.get()['ids']) == 0:
    questions_df = pd.read_csv("qsr_nlp_10000_questions.csv")
    collection.add(documents=questions_df["Question"].tolist(), ids=[f"id_{i}" for i in range(len(questions_df))])

question = st.text_input("Ask a question about store performance:")
if not question:
    st.stop()

# Logic block example
def run_logic_blocks(q, df):
    q = q.lower()
    if "net sales" in q and "fy" in q:
        try:
            fy = [s for s in q.split() if s.upper().startswith("FY")][0]
            fy_year = int(fy[-2:])
            start = pd.Timestamp(f"20{fy_year - 1}-04-01")
            end = pd.Timestamp(f"20{fy_year}-03-31")
            result = df[(df['Metric'].str.lower() == 'net sales') & (df['Month'] >= start) & (df['Month'] <= end)]
            return result.groupby("Store")["Amount"].sum().reset_index().sort_values(by="Amount", ascending=False)
        except:
            return None
    return None

# Run logic first
logic_result = run_logic_blocks(question, df)
if isinstance(logic_result, pd.DataFrame) and not logic_result.empty:
    st.success("Answer generated by logic engine")
    st.dataframe(logic_result)
else:
    search_result = collection.query(query_texts=[question], n_results=3)
    top_match = search_result['documents'][0][0]
    prompt = f"Question: {question}

Similar CEO question: {top_match}

Based on QSR performance data: Month, Store, Metric, Amount.
Respond clearly."
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        st.markdown("**🤖 GPT Answer:**")
        st.markdown(response.choices[0].message.content)
    except Exception as e:
        st.error(f"GPT Error: {e}")